import { Pinecone } from "@pinecone-database/pinecone";

export default async function handler(req, res) {
  // 1. ë³´ì•ˆ: POST ìš”ì²­ë§Œ ë°›ìŒ
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method Not Allowed' });
  }

  try {
    const { message } = req.body;
    
    const googleApiKey = process.env.GOOGLE_API_KEY;
    const openaiApiKey = process.env.OPENAI_API_KEY;

    if (!googleApiKey || !openaiApiKey) {
        throw new Error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
    }

    // 2. ì„ë² ë”© (êµ¬ê¸€)
    const embeddingResponse = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:embedContent?key=${googleApiKey}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: "models/text-embedding-004",
          content: { parts: [{ text: message }] }
        })
      }
    );

    if (!embeddingResponse.ok) throw new Error("êµ¬ê¸€ ì„ë² ë”© ì‹¤íŒ¨");

    const embeddingData = await embeddingResponse.json();
    const queryVector = embeddingData.embedding.values;

    // 3. íŒŒì¸ì½˜ ê²€ìƒ‰
    const pinecone = new Pinecone({ apiKey: process.env.PINECONE_API_KEY });
    const index = pinecone.index(process.env.PINECONE_INDEX_NAME);
    
    const queryResponse = await index.query({
      vector: queryVector,
      topK: 3,
      includeMetadata: true,
    });

    const context = queryResponse.matches.map((match) => match.metadata.text).join("\n\n");
    console.log("íŒŒì¸ì½˜ ê²€ìƒ‰(RAG) ì„±ê³µ:", context);

    // 4. OpenAI ë‹µë³€ ìƒì„±
    const systemPrompt = `
    ë‹¹ì‹ ì€ ë°ì¼ ì¹´ë„¤ê¸° ì¸ê°„ê´€ê³„ë¡  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ [ì°¸ê³  ìë£Œ]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê²Œ ì¡°ì–¸í•´ì£¼ì„¸ìš”.
    
    [ì°¸ê³  ìë£Œ]
    ${context}
    
    ë‹µë³€ ëì— "ğŸ¥•(OpenAI)"ë¥¼ ê¼­ ë¶™ì—¬ì£¼ì„¸ìš”.
    `;

    const chatResponse = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${openaiApiKey}`
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: message }
        ],
        temperature: 0.7
      })
    });

    if (!chatResponse.ok) {
        const err = await chatResponse.text();
        throw new Error(`OpenAI Error: ${err}`);
    }

    const chatData = await chatResponse.json();
    const aiText = chatData.choices[0].message.content;

    // â˜…â˜…â˜… ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì •! â˜…â˜…â˜…
    // í™”ë©´ì´ í•˜ì–—ê²Œ ë˜ì§€ ì•Šë„ë¡, í™”ë©´ì´ ì›í•˜ëŠ” 'ì¢…í•© ì„ ë¬¼ ì„¸íŠ¸(JSON)' ëª¨ì–‘ì„ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.
    const result = {
      // 1. ì ìˆ˜ (ì¼ë‹¨ ëœë¤ì´ë‚˜ ê³ ì •ê°’ìœ¼ë¡œ ë„£ì–´ì¤Œ)
      intimacyScore: 85,
      balanceRatio: { speaker1: 50, speaker2: 50 },
      sentiment: { positive: 60, neutral: 20, negative: 20 },
      averageResponseTime: { speaker1: 5, speaker2: 10 },
      
      // 2. ì œëª© ë° ìš”ì•½
      summary: "ì¹´ë„¤ê¸° ì±—ë´‡ì˜ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.",
      
      // 3. â˜… OpenAIê°€ ë§Œë“  ë‹µë³€ì„ ì—¬ê¸°ì— ë„£ìŠµë‹ˆë‹¤!
      recommendation: aiText,
      
      // 4. ê·¸ë˜í”„ìš© ë”ë¯¸ ë°ì´í„° (í™”ë©´ ê¹¨ì§ ë°©ì§€)
      sentimentFlow: Array(20).fill(null).map((_, i) => ({ time_percentage: i * 5, sentiment_score: 0.5 })),
      responseHeatmap: Array(24).fill(0),
      
      // 5. ì¶”ì²œ ëŒ€ë‹µ
      suggestedReplies: ["ê·¸ë ‡êµ°ìš”.", "ì¢‹ì€ ì¡°ì–¸ ê°ì‚¬í•©ë‹ˆë‹¤.", "ë…¸ë ¥í•´ë³¼ê²Œìš”."],
      suggestedTopics: ["ëŒ€í™”ë²•", "ì¸ê°„ê´€ê³„", "ê²½ì²­"]
    };

    // í¬ì¥ëœ ë°ì´í„°ë¥¼ ë³´ëƒ…ë‹ˆë‹¤.
    return res.status(200).json(result);

  } catch (error) {
    console.error("ì„œë²„ ì—ëŸ¬:", error);
    return res.status(500).json({ error: error.message });
  }
}
